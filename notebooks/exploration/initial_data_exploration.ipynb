{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Exploration for Retail Analytics\n",
    "\n",
    "This notebook performs an initial exploratory data analysis on our retail dataset, examining the main entities:\n",
    "- Customers\n",
    "- Products\n",
    "- Transactions\n",
    "- Transaction Items\n",
    "\n",
    "The goal is to understand the data structure, identify patterns, and gain insights for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# Configure plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "# Add project root to path for importing custom modules\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "# Configure pandas display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "First, let's load the retail datasets. We'll support both real data from external sources and simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_data(data_dir, entity_name, file_pattern='*_{}_*.csv'):\n",
    "    \"\"\"\n",
    "    Load the latest data file for a given entity.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing data files\n",
    "        entity_name: Name of the entity (e.g., 'customers', 'products')\n",
    "        file_pattern: Pattern to match files, with {} placeholder for entity_name\n",
    "        \n",
    "    Returns:\n",
    "        Latest DataFrame for the entity\n",
    "    \"\"\"\n",
    "    pattern = file_pattern.format(entity_name)\n",
    "    files = glob.glob(os.path.join(data_dir, pattern))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files found for {entity_name} in {data_dir} with pattern {pattern}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort files by timestamp (assuming filenames contain timestamp)\n",
    "    latest_file = sorted(files)[-1]\n",
    "    print(f\"Loading {entity_name} data from {os.path.basename(latest_file)}\")\n",
    "    \n",
    "    # Read data based on file extension\n",
    "    file_ext = os.path.splitext(latest_file)[1].lower()\n",
    "    \n",
    "    if file_ext == '.csv':\n",
    "        return pd.read_csv(latest_file)\n",
    "    elif file_ext == '.json':\n",
    "        return pd.read_json(latest_file, lines=True)\n",
    "    elif file_ext == '.parquet':\n",
    "        return pd.read_parquet(latest_file)\n",
    "    else:\n",
    "        print(f\"Unsupported file extension: {file_ext}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files found for customers in ../../data/simulated with pattern *_customers_*.csv\n",
      "No files found for products in ../../data/simulated with pattern *_products_*.csv\n",
      "No files found for locations in ../../data/simulated with pattern *_locations_*.csv\n",
      "No files found for transactions in ../../data/simulated with pattern *_transactions_*.csv\n",
      "No files found for transaction_items in ../../data/simulated with pattern *_transaction_items_*.csv\n"
     ]
    }
   ],
   "source": [
    "# Load data from simulated data directory\n",
    "DATA_DIR = '../../data/simulated'\n",
    "\n",
    "entities = ['customers', 'products', 'locations', 'transactions', 'transaction_items']\n",
    "data = {}\n",
    "\n",
    "for entity in entities:\n",
    "    data[entity] = load_latest_data(DATA_DIR, entity)\n",
    "    \n",
    "# Check which entities were loaded\n",
    "for entity, df in data.items():\n",
    "    if df is not None:\n",
    "        print(f\"{entity}: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Let's examine the structure and content of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe(df, name):\n",
    "    \"\"\"\n",
    "    Print analysis of a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to analyze\n",
    "        name: Name of the dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analysis of {name} dataset\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nSample Records:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    display(df.describe(include='all').T)\n",
    "    \n",
    "    print(\"\\nMissing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    print(missing[missing > 0] if any(missing > 0) else \"No missing values\")\n",
    "    \n",
    "    print(\"\\nUnique Values in Each Column:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' or df[col].nunique() < 20:\n",
    "            print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "            if df[col].nunique() < 10:\n",
    "                print(f\"  Values: {sorted(df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each dataset\n",
    "for entity, df in data.items():\n",
    "    if df is not None:\n",
    "        analyze_dataframe(df, entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Analysis\n",
    "\n",
    "Let's analyze the customer data to understand the customer base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'customers' in data and data['customers'] is not None:\n",
    "    customers_df = data['customers']\n",
    "    \n",
    "    # Active vs. Inactive customers\n",
    "    if 'is_active' in customers_df.columns:\n",
    "        activity_counts = customers_df['is_active'].value_counts()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = activity_counts.plot(kind='pie', autopct='%1.1f%%', colors=['#ff9999','#66b3ff'])\n",
    "        ax.set_ylabel('')\n",
    "        plt.title('Active vs. Inactive Customers')\n",
    "        plt.show()\n",
    "    \n",
    "    # Customer creation date analysis\n",
    "    if 'created_at' in customers_df.columns:\n",
    "        try:\n",
    "            # Convert to datetime if not already\n",
    "            if not pd.api.types.is_datetime64_any_dtype(customers_df['created_at']):\n",
    "                customers_df['created_at'] = pd.to_datetime(customers_df['created_at'])\n",
    "            \n",
    "            # Create month-year field\n",
    "            customers_df['registration_month'] = customers_df['created_at'].dt.to_period('M')\n",
    "            \n",
    "            # Plot customer registrations by month\n",
    "            monthly_registrations = customers_df.groupby('registration_month').size()\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            monthly_registrations.plot(kind='bar', color='skyblue')\n",
    "            plt.title('Customer Registrations by Month')\n",
    "            plt.xlabel('Month')\n",
    "            plt.ylabel('Number of Registrations')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing customer creation dates: {e}\")\n",
    "else:\n",
    "    print(\"No customer data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Analysis\n",
    "\n",
    "Let's analyze the product data to understand the product catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'products' in data and data['products'] is not None:\n",
    "    products_df = data['products']\n",
    "    \n",
    "    # Product categories distribution\n",
    "    if 'category' in products_df.columns:\n",
    "        category_counts = products_df['category'].value_counts().head(10)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = category_counts.plot(kind='barh', color='lightgreen')\n",
    "        plt.title('Top 10 Product Categories')\n",
    "        plt.xlabel('Number of Products')\n",
    "        plt.ylabel('Category')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Brand distribution\n",
    "    if 'brand' in products_df.columns:\n",
    "        brand_counts = products_df['brand'].value_counts().head(10)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = brand_counts.plot(kind='barh', color='salmon')\n",
    "        plt.title('Top 10 Brands')\n",
    "        plt.xlabel('Number of Products')\n",
    "        plt.ylabel('Brand')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Price distribution\n",
    "    if 'unit_price' in products_df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(products_df['unit_price'], bins=30, kde=True)\n",
    "        plt.title('Product Price Distribution')\n",
    "        plt.xlabel('Price')\n",
    "        \n",
    "        # Box plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(y=products_df['unit_price'])\n",
    "        plt.title('Price Box Plot')\n",
    "        plt.ylabel('Price')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Price statistics\n",
    "        price_stats = products_df['unit_price'].describe()\n",
    "        print(\"Price Statistics:\")\n",
    "        print(price_stats)\n",
    "        \n",
    "        # Price by category\n",
    "        if 'category' in products_df.columns:\n",
    "            top_categories = products_df['category'].value_counts().head(5).index\n",
    "            category_prices = products_df[products_df['category'].isin(top_categories)]\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(x='category', y='unit_price', data=category_prices)\n",
    "            plt.title('Price Distribution by Top 5 Categories')\n",
    "            plt.xlabel('Category')\n",
    "            plt.ylabel('Price')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No product data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Analysis\n",
    "\n",
    "Let's analyze the transactions to understand purchasing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(entity in data and data[entity] is not None for entity in ['transactions', 'transaction_items']):\n",
    "    transactions_df = data['transactions']\n",
    "    transaction_items_df = data['transaction_items']\n",
    "    \n",
    "    # Prepare transaction date if needed\n",
    "    if 'created_at' in transactions_df.columns and not pd.api.types.is_datetime64_any_dtype(transactions_df['created_at']):\n",
    "        transactions_df['created_at'] = pd.to_datetime(transactions_df['created_at'])\n",
    "    \n",
    "    # Transactions by date\n",
    "    if 'created_at' in transactions_df.columns:\n",
    "        transactions_df['transaction_date'] = transactions_df['created_at'].dt.date\n",
    "        daily_transactions = transactions_df.groupby('transaction_date').size()\n",
    "        \n",
    "        plt.figure(figsize=(14, 6))\n",
    "        daily_transactions.plot()\n",
    "        plt.title('Number of Transactions by Date')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Number of Transactions')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Transaction amount distribution\n",
    "    if 'total_amount' in transactions_df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(transactions_df['total_amount'], bins=30, kde=True)\n",
    "        plt.title('Transaction Amount Distribution')\n",
    "        plt.xlabel('Amount')\n",
    "        \n",
    "        # Box plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(y=transactions_df['total_amount'])\n",
    "        plt.title('Amount Box Plot')\n",
    "        plt.ylabel('Amount')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Transaction amount statistics\n",
    "        amount_stats = transactions_df['total_amount'].describe()\n",
    "        print(\"Transaction Amount Statistics:\")\n",
    "        print(amount_stats)\n",
    "    \n",
    "    # Payment method distribution\n",
    "    if 'payment_method' in transactions_df.columns:\n",
    "        payment_counts = transactions_df['payment_method'].value_counts()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = payment_counts.plot(kind='pie', autopct='%1.1f%%', cmap='tab10')\n",
    "        ax.set_ylabel('')\n",
    "        plt.title('Payment Method Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Channel distribution\n",
    "    if 'channel' in transactions_df.columns:\n",
    "        channel_counts = transactions_df['channel'].value_counts()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = channel_counts.plot(kind='bar', color='lightblue')\n",
    "        plt.title('Transaction Channel Distribution')\n",
    "        plt.xlabel('Channel')\n",
    "        plt.ylabel('Number of Transactions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Items per transaction\n",
    "    items_per_transaction = transaction_items_df.groupby('transaction_id').size()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(items_per_transaction, bins=20, kde=True)\n",
    "    plt.title('Items per Transaction Distribution')\n",
    "    plt.xlabel('Number of Items')\n",
    "    \n",
    "    # Box plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=items_per_transaction)\n",
    "    plt.title('Items per Transaction Box Plot')\n",
    "    plt.ylabel('Number of Items')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Items per transaction statistics\n",
    "    items_stats = items_per_transaction.describe()\n",
    "    print(\"Items per Transaction Statistics:\")\n",
    "    print(items_stats)\n",
    "else:\n",
    "    print(\"Transaction data or transaction items data not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Purchase Analysis\n",
    "\n",
    "Let's analyze customer purchasing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(entity in data and data[entity] is not None for entity in ['customers', 'transactions']):\n",
    "    customers_df = data['customers']\n",
    "    transactions_df = data['transactions']\n",
    "    \n",
    "    # Merge data\n",
    "    if 'customer_id' in transactions_df.columns:\n",
    "        # Group transactions by customer\n",
    "        customer_transactions = transactions_df.groupby('customer_id').agg({\n",
    "            'transaction_id': 'count',\n",
    "            'total_amount': 'sum',\n",
    "            'created_at': ['min', 'max']\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        customer_transactions.columns = ['transaction_count', 'total_spend', 'first_purchase', 'last_purchase']\n",
    "        \n",
    "        # Calculate average transaction value\n",
    "        customer_transactions['avg_transaction_value'] = customer_transactions['total_spend'] / customer_transactions['transaction_count']\n",
    "        \n",
    "        # Calculate days since first purchase and last purchase\n",
    "        if not pd.api.types.is_datetime64_any_dtype(customer_transactions['first_purchase']):\n",
    "            customer_transactions['first_purchase'] = pd.to_datetime(customer_transactions['first_purchase'])\n",
    "        if not pd.api.types.is_datetime64_any_dtype(customer_transactions['last_purchase']):\n",
    "            customer_transactions['last_purchase'] = pd.to_datetime(customer_transactions['last_purchase'])\n",
    "            \n",
    "        today = pd.Timestamp.now().date()\n",
    "        customer_transactions['days_since_first_purchase'] = (today - customer_transactions['first_purchase'].dt.date).dt.days\n",
    "        customer_transactions['days_since_last_purchase'] = (today - customer_transactions['last_purchase'].dt.date).dt.days\n",
    "        \n",
    "        # Calculate purchase frequency (days between purchases)\n",
    "        customer_transactions['purchase_timespan'] = (customer_transactions['last_purchase'] - customer_transactions['first_purchase']).dt.days\n",
    "        customer_transactions['purchase_frequency'] = customer_transactions['purchase_timespan'] / customer_transactions['transaction_count']\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"Customer Purchase Behavior Summary:\")\n",
    "        display(customer_transactions.describe())\n",
    "        \n",
    "        # Visualize transaction count distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(customer_transactions['transaction_count'], bins=30, kde=True)\n",
    "        plt.title('Distribution of Transaction Count per Customer')\n",
    "        plt.xlabel('Number of Transactions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Visualize total spend distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(customer_transactions['total_spend'], bins=30, kde=True)\n",
    "        plt.title('Distribution of Total Spend per Customer')\n",
    "        plt.xlabel('Total Spend')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # RFM Analysis\n",
    "        print(\"\\nRFM Analysis:\")\n",
    "        \n",
    "        # Create RFM segments\n",
    "        # Recency - days since last purchase\n",
    "        r_labels = ['1-30 days', '31-60 days', '61-90 days', '91-180 days', '181+ days']\n",
    "        r_bins = [0, 30, 60, 90, 180, float('inf')]\n",
    "        customer_transactions['recency_segment'] = pd.cut(customer_transactions['days_since_last_purchase'], bins=r_bins, labels=r_labels)\n",
    "        \n",
    "        # Frequency - number of transactions\n",
    "        f_labels = ['1 transaction', '2-5 transactions', '6-10 transactions', '11-20 transactions', '21+ transactions']\n",
    "        f_bins = [0, 1, 5, 10, 20, float('inf')]\n",
    "        customer_transactions['frequency_segment'] = pd.cut(customer_transactions['transaction_count'], bins=f_bins, labels=f_labels)\n",
    "        \n",
    "        # Monetary - total spend\n",
    "        quantiles = customer_transactions['total_spend'].quantile([0.2, 0.4, 0.6, 0.8])\n",
    "        m_labels = ['Bottom 20%', '20-40%', '40-60%', '60-80%', 'Top 20%']\n",
    "        m_bins = [0, quantiles[0.2], quantiles[0.4], quantiles[0.6], quantiles[0.8], float('inf')]\n",
    "        customer_transactions['monetary_segment'] = pd.cut(customer_transactions['total_spend'], bins=m_bins, labels=m_labels)\n",
    "        \n",
    "        # Display RFM segment distributions\n",
    "        rfm_segments = pd.DataFrame()\n",
    "        rfm_segments['recency'] = customer_transactions['recency_segment'].value_counts()\n",
    "        rfm_segments['frequency'] = customer_transactions['frequency_segment'].value_counts()\n",
    "        rfm_segments['monetary'] = customer_transactions['monetary_segment'].value_counts()\n",
    "        \n",
    "        display(rfm_segments)\n",
    "        \n",
    "        # Visualize RFM segments\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.barplot(x=rfm_segments.index, y=rfm_segments['recency'], palette='Blues_d')\n",
    "        plt.title('Recency Segments')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Number of Customers')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.barplot(x=rfm_segments.index, y=rfm_segments['frequency'], palette='Greens_d')\n",
    "        plt.title('Frequency Segments')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Number of Customers')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.barplot(x=rfm_segments.index, y=rfm_segments['monetary'], palette='Reds_d')\n",
    "        plt.title('Monetary Segments')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Number of Customers')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Customer data or transaction data not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Performance Analysis\n",
    "\n",
    "Let's analyze product performance based on transaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(entity in data and data[entity] is not None for entity in ['products', 'transaction_items']):\n",
    "    products_df = data['products']\n",
    "    transaction_items_df = data['transaction_items']\n",
    "    \n",
    "    # Merge product data with transaction items\n",
    "    if 'product_id' in transaction_items_df.columns and 'product_id' in products_df.columns:\n",
    "        # Group by product to get sales metrics\n",
    "        product_sales = transaction_items_df.groupby('product_id').agg({\n",
    "            'transaction_item_id': 'count',\n",
    "            'quantity': 'sum',\n",
    "            'line_total': 'sum'\n",
    "        }).rename(columns={\n",
    "            'transaction_item_id': 'times_sold',\n",
    "            'quantity': 'units_sold',\n",
    "            'line_total': 'total_revenue'\n",
    "        })\n",
    "        \n",
    "        # Merge with product information\n",
    "        product_performance = product_sales.join(products_df.set_index('product_id')[['product_name', 'category', 'brand', 'unit_price']])\n",
    "        \n",
    "        # Calculate profit (assuming we have cost_price)\n",
    "        if 'cost_price' in products_df.columns:\n",
    "            cost_price_map = products_df.set_index('product_id')['cost_price']\n",
    "            product_performance['cost_price'] = product_performance.index.map(cost_price_map)\n",
    "            product_performance['total_cost'] = product_performance['units_sold'] * product_performance['cost_price']\n",
    "            product_performance['total_profit'] = product_performance['total_revenue'] - product_performance['total_cost']\n",
    "            product_performance['profit_margin'] = product_performance['total_profit'] / product_performance['total_revenue']\n",
    "        \n",
    "        # Sort by revenue to find top performers\n",
    "        top_products = product_performance.sort_values('total_revenue', ascending=False).head(10)\n",
    "        \n",
    "        print(\"Top 10 Products by Revenue:\")\n",
    "        display(top_products[['product_name', 'category', 'brand', 'times_sold', 'units_sold', 'total_revenue']])\n",
    "        \n",
    "        # Visualize top products\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='total_revenue', y='product_name', data=top_products, palette='viridis')\n",
    "        plt.title('Top 10 Products by Revenue')\n",
    "        plt.xlabel('Total Revenue')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Category performance\n",
    "        if 'category' in product_performance.columns:\n",
    "            category_performance = product_performance.groupby('category').agg({\n",
    "                'times_sold': 'sum',\n",
    "                'units_sold': 'sum',\n",
    "                'total_revenue': 'sum'\n",
    "            }).sort_values('total_revenue', ascending=False)\n",
    "            \n",
    "            top_categories = category_performance.head(10)\n",
    "            \n",
    "            print(\"\\nTop 10 Categories by Revenue:\")\n",
    "            display(top_categories)\n",
    "            \n",
    "            # Visualize top categories\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.barplot(x='total_revenue', y=top_categories.index, data=top_categories, palette='plasma')\n",
    "            plt.title('Top 10 Categories by Revenue')\n",
    "            plt.xlabel('Total Revenue')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Brand performance\n",
    "        if 'brand' in product_performance.columns:\n",
    "            brand_performance = product_performance.groupby('brand').agg({\n",
    "                'times_sold': 'sum',\n",
    "                'units_sold': 'sum',\n",
    "                'total_revenue': 'sum'\n",
    "            }).sort_values('total_revenue', ascending=False)\n",
    "            \n",
    "            top_brands = brand_performance.head(10)\n",
    "            \n",
    "            print(\"\\nTop 10 Brands by Revenue:\")\n",
    "            display(top_brands)\n",
    "            \n",
    "            # Visualize top brands\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.barplot(x='total_revenue', y=top_brands.index, data=top_brands, palette='magma')\n",
    "            plt.title('Top 10 Brands by Revenue')\n",
    "            plt.xlabel('Total Revenue')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Profit analysis if available\n",
    "        if 'profit_margin' in product_performance.columns:\n",
    "            # Top products by profit margin (with minimum sales threshold)\n",
    "            min_sales = 5  # Minimum number of sales to consider\n",
    "            top_margin_products = product_performance[product_performance['times_sold'] >= min_sales].sort_values('profit_margin', ascending=False).head(10)\n",
    "            \n",
    "            print(f\"\\nTop 10 Products by Profit Margin (with at least {min_sales} sales):\")\n",
    "            display(top_margin_products[['product_name', 'category', 'times_sold', 'total_revenue', 'total_profit', 'profit_margin']])\n",
    "            \n",
    "            # Visualize profit margin distribution\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.histplot(product_performance['profit_margin'], bins=30, kde=True)\n",
    "            plt.title('Profit Margin Distribution')\n",
    "            plt.xlabel('Profit Margin')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Product data or transaction items data not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Analysis\n",
    "\n",
    "Let's analyze sales patterns by location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(entity in data and data[entity] is not None for entity in ['transactions', 'locations']):\n",
    "    transactions_df = data['transactions']\n",
    "    locations_df = data['locations']\n",
    "    \n",
    "    # Merge transactions with locations\n",
    "    if 'location_id' in transactions_df.columns and 'location_id' in locations_df.columns:\n",
    "        # Merge data\n",
    "        transaction_locations = transactions_df.merge(locations_df, on='location_id')\n",
    "        \n",
    "        # Sales by country\n",
    "        if 'country' in transaction_locations.columns and 'total_amount' in transaction_locations.columns:\n",
    "            country_sales = transaction_locations.groupby('country').agg({\n",
    "                'transaction_id': 'count',\n",
    "                'total_amount': 'sum'\n",
    "            }).rename(columns={\n",
    "                'transaction_id': 'transaction_count',\n",
    "                'total_amount': 'total_sales'\n",
    "            }).sort_values('total_sales', ascending=False)\n",
    "            \n",
    "            print(\"Sales by Country:\")\n",
    "            display(country_sales.head(10))\n",
    "            \n",
    "            # Calculate average transaction value by country\n",
    "            country_sales['avg_transaction_value'] = country_sales['total_sales'] / country_sales['transaction_count']\n",
    "            \n",
    "            # Visualize top countries by sales\n",
    "            top_countries = country_sales.head(10)\n",
    "            \n",
    "            plt.figure(figsize=(14, 10))\n",
    "            \n",
    "            plt.subplot(2, 1, 1)\n",
    "            sns.barplot(x=top_countries.index, y='total_sales', data=top_countries, palette='Blues_d')\n",
    "            plt.title('Top 10 Countries by Sales')\n",
    "            plt.xlabel('Country')\n",
    "            plt.ylabel('Total Sales')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            plt.subplot(2, 1, 2)\n",
    "            sns.barplot(x=top_countries.index, y='avg_transaction_value', data=top_countries, palette='Greens_d')\n",
    "            plt.title('Average Transaction Value by Country')\n",
    "            plt.xlabel('Country')\n",
    "            plt.ylabel('Average Transaction Value')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Sales by state/region\n",
    "        if 'state' in transaction_locations.columns and 'total_amount' in transaction_locations.columns:\n",
    "            # Group by country and state for more meaningful analysis\n",
    "            state_sales = transaction_locations.groupby(['country', 'state']).agg({\n",
    "                'transaction_id': 'count',\n",
    "                'total_amount': 'sum'\n",
    "            }).rename(columns={\n",
    "                'transaction_id': 'transaction_count',\n",
    "                'total_amount': 'total_sales'\n",
    "            }).sort_values('total_sales', ascending=False)\n",
    "            \n",
    "            print(\"\\nSales by State/Region:\")\n",
    "            display(state_sales.head(10))\n",
    "            \n",
    "            # For visualization, get top states overall\n",
    "            top_states = state_sales.head(10).reset_index()\n",
    "            \n",
    "            plt.figure(figsize=(14, 6))\n",
    "            sns.barplot(x='state', y='total_sales', hue='country', data=top_states, palette='Set2')\n",
    "            plt.title('Top 10 States/Regions by Sales')\n",
    "            plt.xlabel('State/Region')\n",
    "            plt.ylabel('Total Sales')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(title='Country')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Transaction data or location data not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Based Analysis\n",
    "\n",
    "Let's analyze sales patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'transactions' in data and data['transactions'] is not None:\n",
    "    transactions_df = data['transactions']\n",
    "    \n",
    "    # Ensure transaction date is in datetime format\n",
    "    if 'created_at' in transactions_df.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(transactions_df['created_at']):\n",
    "            transactions_df['created_at'] = pd.to_datetime(transactions_df['created_at'])\n",
    "        \n",
    "        # Create time-based fields\n",
    "        transactions_df['date'] = transactions_df['created_at'].dt.date\n",
    "        transactions_df['month'] = transactions_df['created_at'].dt.to_period('M')\n",
    "        transactions_df['day_of_week'] = transactions_df['created_at'].dt.day_name()\n",
    "        transactions_df['hour'] = transactions_df['created_at'].dt.hour\n",
    "        \n",
    "        # Sales by month\n",
    "        monthly_sales = transactions_df.groupby('month').agg({\n",
    "            'transaction_id': 'count',\n",
    "            'total_amount': 'sum'\n",
    "        }).rename(columns={\n",
    "            'transaction_id': 'transaction_count',\n",
    "            'total_amount': 'total_sales'\n",
    "        })\n",
    "        \n",
    "        # Plot monthly sales trend\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        ax = monthly_sales['total_sales'].plot(color='blue', marker='o')\n",
    "        ax2 = ax.twinx()\n",
    "        monthly_sales['transaction_count'].plot(color='red', marker='x', ax=ax2)\n",
    "        ax.set_xlabel('Month')\n",
    "        ax.set_ylabel('Total Sales', color='blue')\n",
    "        ax2.set_ylabel('Transaction Count', color='red')\n",
    "        plt.title('Monthly Sales and Transaction Count')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Sales by day of week\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        daily_sales = transactions_df.groupby('day_of_week').agg({\n",
    "            'transaction_id': 'count',\n",
    "            'total_amount': 'sum'\n",
    "        }).rename(columns={\n",
    "            'transaction_id': 'transaction_count',\n",
    "            'total_amount': 'total_sales'\n",
    "        }).reindex(day_order)\n",
    "        \n",
    "        # Plot sales by day of week\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x=daily_sales.index, y='total_sales', data=daily_sales, palette='Blues_d')\n",
    "        plt.title('Sales by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('Total Sales')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.barplot(x=daily_sales.index, y='transaction_count', data=daily_sales, palette='Greens_d')\n",
    "        plt.title('Transaction Count by Day of Week')\n",
    "        plt.xlabel('Day of Week')\n",
    "        plt.ylabel('Transaction Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Sales by hour of day\n",
    "        hourly_sales = transactions_df.groupby('hour').agg({\n",
    "            'transaction_id': 'count',\n",
    "            'total_amount': 'sum'\n",
    "        }).rename(columns={\n",
    "            'transaction_id': 'transaction_count',\n",
    "            'total_amount': 'total_sales'\n",
    "        })\n",
    "        \n",
    "        # Plot sales by hour\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x=hourly_sales.index, y='total_sales', data=hourly_sales, palette='Blues_d')\n",
    "        plt.title('Sales by Hour of Day')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('Total Sales')\n",
    "        plt.xticks(range(0, 24, 2))\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.barplot(x=hourly_sales.index, y='transaction_count', data=hourly_sales, palette='Greens_d')\n",
    "        plt.title('Transaction Count by Hour of Day')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('Transaction Count')\n",
    "        plt.xticks(range(0, 24, 2))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Transaction data not available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "This exploratory data analysis has provided valuable insights into our retail data. Key findings include:\n",
    "\n",
    "1. **Customer Behavior**: We've identified customer segments based on recency, frequency, and monetary value (RFM analysis).\n",
    "\n",
    "2. **Product Performance**: We've identified top-performing products, categories, and brands by revenue and profit margin.\n",
    "\n",
    "3. **Geographic Patterns**: We've analyzed sales patterns across different locations to identify high-value markets.\n",
    "\n",
    "4. **Temporal Patterns**: We've discovered sales trends by month, day of week, and hour of day.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Feature Engineering**: Based on these insights, we can create features for our machine learning models, such as:\n",
    "   - RFM scores for customer segmentation\n",
    "   - Product popularity and profitability metrics\n",
    "   - Seasonal indicators for demand forecasting\n",
    "\n",
    "2. **Data Preprocessing**: Address any data quality issues identified during analysis:\n",
    "   - Handle missing values\n",
    "   - Standardize categorical variables\n",
    "   - Create appropriate date/time features\n",
    "\n",
    "3. **Advanced Analytics**: Develop more sophisticated analyses:\n",
    "   - Market basket analysis to identify product associations\n",
    "   - Customer lifetime value prediction\n",
    "   - Churn risk identification\n",
    "   - Price elasticity modeling\n",
    "\n",
    "4. **Model Development**: Begin building machine learning models for:\n",
    "   - Customer segmentation\n",
    "   - Product recommendation\n",
    "   - Demand forecasting\n",
    "   \n",
    "5. **Dashboard Development**: Create interactive dashboards for key metrics and insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
